[{"authors":null,"categories":null,"content":"I am Reza, a data scientist and statistician with a PhD in Statistics from the University of Waterloo. My research interests revolve around the intersection of data science, statistics, and AI technologies. Specifically, I am passionate about exploring machine learning approaches, leveraging AI techniques, and developing innovative solutions in the field of data analysis and prediction.\n","date":1694304e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1694304e3,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am Reza, a data scientist and statistician with a PhD in Statistics from the University of Waterloo. My research interests revolve around the intersection of data science, statistics, and AI technologies.","tags":null,"title":"Reza Mehrzi","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://rezamehrizi.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Chen Sun","Yaodong Cui","Ng·ªçc-D≈©ng ƒê√†o","Reza Mehrzi","Mohammad Pirani","Amir Khajepour"],"categories":null,"content":"","date":1694304e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694304e3,"objectID":"d2cbc3901c1d3ab7b19d78407d232688","permalink":"https://rezamehrizi.github.io/publication/chen-fidelity-23/","publishdate":"2023-09-10T00:00:00Z","relpermalink":"/publication/chen-fidelity-23/","section":"publication","summary":"This paper addresses challenges in testing Automated Driving System (ADS) functions, proposing a novel medium-fidelity evaluation and modeling approach. It aims to scale testing processes and improve test case interpretability, given the complexity of ADS setups. The proposed framework uses a statistical model to handle uncertainty and errors in perception systems, encoding error propagation in space and time. Operating conditions, including hardware, software configurations, and safety parameters, are described and evaluated with real-world and simulated data. The paper offers a promising solution for effective ADS testing and continual learning.","tags":["Source Themes"],"title":"Medium-Fidelity Evaluation and Modeling for Perception Systems of Intelligent and Connected Vehicles","type":"publication"},{"authors":null,"categories":null,"content":" The impact of AI has been growing rapidly, with the introduction of ChatGPT being a significant contributor to this trend. As we look ahead, the AI landscape is poised for exciting and transformative changes. Hence, in this project, my focus will be on gathering data from YouTube videos related to Artificial Intelligence (AI). The project involves three main tasks as follows:\nYouTube Videos Web Scrapping: I‚Äôll craft a Python script designed to tap into the YouTube API, allowing me to extract information from videos tied to the AI theme.\nPre-processing Videos Dataset Once I‚Äôve got the data in hand, I‚Äôll smoothly slide it into a pandas data frame for better organization.\nDescriptive Analysis of Videos Dataset: My next steps involve diving into analysis and visualizations, keeping things simple with the helpful Plotly Python library.\nWeb Scrapping YouTube Videos Dataset To kick things off, I‚Äôll go through the process of generating YouTube API key. Once that‚Äôs in place, I‚Äôll navigate through Google‚Äôs detailed YouTube API documentation to access various YouTube data. With that, I‚Äôll move on to crafting the Python code that forms the foundation of this section.\nAPI Key from Google: The first step involves creating a Google API key. I start by visiting the Google Developer Console through my browser. Once there, I sign in using my Google account. Upon signing in, I click the ‚ÄúCreate a Project‚Äù button. Creating a project is a priority here, and I have options: I can either click the button or go to ‚ÄúSelect a Project‚Äù at the top. Now, I create a fresh project, named ‚ÄúYouTube Analysis Project‚Äù and hit ‚ÄúCreate‚Äù. Giving it a few seconds to come to life. Next, it‚Äôs time to enable the API. In the Library, I search for the API I‚Äôm aiming for ‚Äì in this case, the YouTube Data API. I give it the green light by clicking ‚ÄúEnable.‚Äù Now, onto the final touch: crafting my API key. I slide over to the ‚ÄúCredentials‚Äù section on the left side and click ‚ÄúCreate Credential.‚Äù For my project, I‚Äôm sticking with an API key ‚Äì no need for the OAuth client ID.\nMake API Requests: After I obtained my API key, I used it to authenticate my requests to the YouTube Data API. This key acted like my digital pass that let the API know I was authorized to access its resources. The YouTube Data API has various ‚Äúendpoints‚Äù that correspond to different types of data or actions. For my project, I focused on the ‚Äúsearch‚Äù endpoint, which allowed me to find videos based on specific search criteria. I constructed a request to this endpoint, specifying parameters like my API key and the search query ‚ÄúArtificial Intelligence‚Äù and ‚ÄúAI‚Äù.\nRequest Parameters: API requests can be personalized by adding parameters. These parameters helped me tailor my request to my specific needs. For instance, I adjusted the number of results per page by setting the ‚ÄúmaxResults‚Äù parameter. These parameters gave me flexibility in how I retrieved the data.\nsearch_keywords = \u0026#39;Artificial+Intelligence\u0026#39;+\u0026#39;AI\u0026#39; params = { \u0026#39;part\u0026#39;: \u0026#39;snippet\u0026#39;, # Retrieve basic video information \u0026#39;q\u0026#39;: \u0026#39;artificial intelligence\u0026#39;, # Search term \u0026#39;maxResults\u0026#39;: 1000, # Number of results per page \u0026#39;key\u0026#39;: API_KEY # Your API key } The provided code snippet is setting up parameters for making a search request to the YouTube Data API. params = {...} is a Python dictionary that stores the parameters needed for the API request. Here is the breakdown for this dictionary:\n\u0026#39;part\u0026#39;: \u0026#39;snippet\u0026#39;: This parameter specifies that we want to retrieve basic information about the videos, like their titles, descriptions, and thumbnails. The \u0026#39;snippet\u0026#39; part is required in most API requests. \u0026#39;q\u0026#39;: \u0026#39;search_keywords\u0026#39;: This is the search term I‚Äôm looking for on YouTube. In this case, it‚Äôs search_keywords = \u0026#39;Artificial+Intelligence\u0026#39;+\u0026#39;AI\u0026#39;. \u0026#39;maxResults\u0026#39;: 1000: This parameter indicates the maximum number of results I want per page. The value 1000 suggests you want to retrieve up to 1000 videos per page of the search results. \u0026#39;key\u0026#39;: API_KEY: This is where I would insert my actual YouTube Data API key. The API key serves as my authentication to access the API. So, all together, this code is preparing the parameters for a YouTube Data API search request. It‚Äôs set up to search for videos related to ‚Äúartificial intelligence‚Äù and ‚ÄúAI,‚Äù retrieve basic information about those videos (like titles and descriptions), and return up to 1000 results per page. The API_KEY should be replaced with my actual YouTube Data API key for proper authentication.\nParsing API Responses: When I made a request to the API, it responded with data in JSON format. JSON is a structured way of representing data that‚Äôs easy for both humans and machines to understand. My task was to parse (read and interpret) this JSON response.\nBASE_URL = \u0026#39;https://www.googleapis.com/youtube/v3/search\u0026#39; response = requests.get(BASE_URL, params=params) data = response.json() search_keywords = \u0026#39;Artificial+Intelligence\u0026#39;+\u0026#39;AI\u0026#39; params = { \u0026#39;part\u0026#39;: \u0026#39;snippet\u0026#39;, # Retrieve basic video information \u0026#39;q\u0026#39;: \u0026#39;artificial ‚Ä¶","date":1693180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693180800,"objectID":"984dd918e203a35f8a3a6fd96a0f5749","permalink":"https://rezamehrizi.github.io/project/web-scrapping/","publishdate":"2023-08-28T00:00:00Z","relpermalink":"/project/web-scrapping/","section":"project","summary":"This project scrapes detailed data from AI-related videos on YouTube and offers visualization insights based on the collected information.","tags":["Data Science","Web Scraping","SQL","Sentiment Analysis","Deep Learning"],"title":"Web Scraping Insights from AI Related YouTube Videos","type":"project"},{"authors":null,"categories":null,"content":" Visit My Streamlit Website In this project, I will be working on a Python-based project that focuses on analyzing YouTube videos. This comprehensive project involves various essential aspects such as transcribing, summarizing, and analyzing the content. Transcription: In the transcription phase, I am implementing automated tools to convert the spoken content of YouTube videos into written text. This allows for a detailed and accurate representation of the video‚Äôs dialogue or narration.\nSummarization: The summarization component involves the extraction of essential information from the transcribed text. Using advanced techniques, I aim to provide concise and coherent summaries of the video‚Äôs content, making it more accessible and digestible for viewers.\nContent Analysis: Beyond transcription and summarization, my project delves into comprehensive content analysis. This includes examining various aspects such as sensitivity, topics, sentiment, and entities discussed within the video.\nSensitivity Analysis: I am working on tools to assess the sensitivity of the video‚Äôs content, highlighting potentially controversial or sensitive subjects.\nTopic Analysis: The project identifies and categorizes the main topics and themes covered in the video, allowing for a deeper understanding of its subject matter.\nSentiment Analysis: Through sentiment analysis, I aim to determine the emotional tone and sentiment expressed in the video, whether it‚Äôs positive, negative, neutral, or a blend of these.\nEntity Analysis: This component identifies and analyzes specific individuals, organizations, locations, or noteworthy subjects mentioned in the video, providing insights into key figures or entities related to the content.\nBy combining these elements, my project aims to enhance the accessibility and comprehension of YouTube videos, offering valuable insights and summaries to viewers.\nThe following is the list of the tools and libraries commonly used for the tasks of YouTube video transcription, summarization, and content analysis in Python:\npytube: Pytube is a Python library for downloading YouTube videos. It allows you to fetch video data, including audio streams, which can be used for transcription.\nAssemblyAI: AssemblyAI is an API service that provides automatic speech recognition (ASR) for transcribing audio content, including YouTube video audio. It offers accurate transcription results and supports various languages.\nGoogle Cloud Speech-to-Text: Google‚Äôs Speech-to-Text API can be used for transcribing audio content from YouTube videos. It‚Äôs a cloud-based service that offers robust speech recognition capabilities.\nNatural Language Toolkit (NLTK): NLTK is a powerful library for natural language processing in Python. It can be used to implement extractive text summarization techniques to generate concise summaries from transcribed text.\nGensim: Gensim is another Python library that provides tools for topic modeling and text summarization. It‚Äôs suitable for abstractive summarization approaches as well.\nSpaCy: SpaCy is a popular library for natural language processing tasks, including entity recognition. It can help identify and classify entities (e.g., people, organizations, locations) mentioned in the text.\nI am leveraging the combination of pytube and AssemblyAI to create this YouTube video analysis web in Python.\nThis project takes a YouTube video link as input and performs the content analysis. The project‚Äôs results are presented on a website built with Streamlit, making it easy to access and explore the insights derived from the video‚Äôs content.\nTake a moment to explore this Streamlit web application and discover the insights it provides from the YouTube videos you input. Simply click the link below to get started!\nVisit My Streamlit Website ","date":1692057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692057600,"objectID":"1331628aa1410d6f994721adcb8ac315","permalink":"https://rezamehrizi.github.io/project/nlp/","publishdate":"2023-08-15T00:00:00Z","relpermalink":"/project/nlp/","section":"project","summary":"This project involves YouTube video transcription, summarization, and content analysis which empower users to extract valuable insights, save time, and enhance their understanding of video content. These tools are invaluable for content creators, researchers, and anyone looking to navigate the rich and diverse world of YouTube videos with ease and efficiency.","tags":["NLP","Transcription","Summarizarion","Sentiment Analysis"],"title":"Video Transcription, Summarization, and Content Analysis","type":"project"},{"authors":["Keqi Shu","Reza Mehrzi","Shen Li","Mohammad Pirani","Amir Khajepour"],"categories":null,"content":"","date":1686528e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686528e3,"objectID":"e742187ea36c14a88e5db8c319a32de4","permalink":"https://rezamehrizi.github.io/publication/journal-article1/","publishdate":"2023-06-12T00:00:00Z","relpermalink":"/publication/journal-article1/","section":"publication","summary":"This paper presents a novel framework for autonomous vehicles' left-turning at intersections. It accounts for complex interactions with human drivers and pedestrians by formulating the problem as a mathematical game. Realistic modeling of diverse traffic behaviors, extracted from naturalistic driving data, enables accurate estimation and interaction, leading to effective and human-like decision-making for autonomous vehicles in intersection scenarios.","tags":["Source Themes"],"title":"Human Inspired Autonomous Intersection Handling Using Game Theory","type":"publication"},{"authors":null,"categories":null,"content":" Object detection is a computer vision technique that involves identifying and locating objects of interest within images or videos. It allows machines to not only recognize what objects are present but also precisely determine their positions through bounding boxes. Recent applications of object detection have been groundbreaking, ranging from autonomous vehicles, where it‚Äôs used to detect pedestrians and other vehicles for safe driving, to surveillance systems, enabling real-time monitoring and security alerts. In retail, it‚Äôs employed for shelf inventory management, and in healthcare, it aids in medical image analysis, such as identifying anomalies in X-rays. Moreover, it plays a vital role in enabling augmented reality experiences and interactive gaming, ushering in a new era of user interaction and engagement.\nThe purpose of this project is to deploy a Python-based application for object detection within both images and videos. Leveraging the powerful capabilities of the OpenCV library, this code employs a range of its methods to accurately locate and track objects of interest. By harnessing OpenCV‚Äôs extensive functionality, my project aims to provide an application for object detection, serving various applications including surveillance, image analysis, and interactive experiences. The project‚Äôs outline encompasses the implementation of OpenCV‚Äôs object detection techniques, customization for specific use cases, and the seamless integration of object tracking within videos.\nThe following code demonstrates how to perform object detection on both a static image and a video stream using a pre-trained model and OpenCV. It loads the model, reads class labels, sets input parameters, performs detection, and visualizes the results. Let‚Äôs first import the necessary libraries: OpenCV for computer vision, NumPy for numerical operations.\nimport cv2 import numpy as np Next, we load a pre-trained object detection model in OpenCV. It uses the ‚Äòfrozen_inference_graph.pb‚Äô file as the model‚Äôs weights and ‚Äòssd_mobilenet_v3_large_coco_2020_01_14.pbtxt‚Äô as the model‚Äôs configuration file.\nmodel = cv2.dnn_DetectionModel(\u0026#39;frozen_inference_graph.pb\u0026#39;, \u0026#39;ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\u0026#39;) We also read the class labels from a ‚Äôlabels.txt‚Äô file, which contains the names of the classes the model can detect.\nclassLables = [] file_name = \u0026#39;labels.txt\u0026#39; with open(file_name, \u0026#39;rt\u0026#39;) as fpt: classLabels = fpt.read().rstrip(\u0026#39;\\\\n\u0026#39;).split(\u0026#39;\\\\n\u0026#39;) Then, we set various input parameters for the model:\nsetInputSize(320, 320): Specifies the input size for the model. setInputScale(1.0/127.5): Scales the input pixel values. setInputMean((127.5, 127.5, 127.5)): Sets the mean subtraction values for input preprocessing. setInputSwapRB(True): Swaps the Red and Blue channels in the input image. model.setInputSize(320, 320) model.setInputScale(1.0/127.5) model.setInputMean((127.5, 127.5, 127.5)) model.setInputSwapRB(True) Once the setup is done, it is time to read an input image or video and start detecting objects. Let‚Äôs begin with an image (‚Äòimage1.png‚Äô).\nimg = cv2.imread(\u0026#39;image1.png\u0026#39;) The image can be displayed using OpenCV.\ncv2.imshow(\u0026#39;Image\u0026#39;, img) cv2.waitKey(0) cv2.destroyAllWindows() The following line of code performs object detection on the image using the pre-trained model with a confidence threshold of 0.5. It returns the class indices, confidence scores, and bounding boxes of detected objects.\nClassIndex, confidence, bbox = model.detect(img, confThreshold=0.5) We then loop through the detected objects and draws bounding boxes around them with their corresponding class labels and confidence scores on the input image.\nfont_scale = 3 font = cv2.FONT_HERSHEY_PLAIN for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox): cv2.rectangle(img, boxes, (255, 0, 0, 2)) cv2.putText(img, classLabels[ClassInd - 1], (boxes[0]+10, boxes[1]+40), font, fontScale=font_scale, color=(0, 255, 0), thickness=3) And, finally, we display and save the input image with the detected objects.\ncv2.imshow(\u0026#39;Image with detected objects\u0026#39;, cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) cv2.waitKey(0) cv2.destroyAllWindows() cv2.imwrite(\u0026#39;new_image.png\u0026#39;, img) Now, let‚Äôs explore how to apply a similar approach to a video. The following lines of codes open a video capture using ‚Äòvideo1.mp4‚Äô and falls back to the default camera (if ‚Äòvideo1.mp4‚Äô is not found).\ncap = cv2.VideoCapture(\u0026#39;video1.mp4\u0026#39;) if not cap.isOpened(): cap = cv2.VideoCapture(0) if not cap.isOpened(): raise IOError(\u0026#39;Cant open the video\u0026#39;) Next, we loop through frames in the video, performs object detection on each frame, and displays the frame with bounding boxes and class labels for detected objects. Once we‚Äôre done, we press ‚Äòq‚Äô to exit the video window.\nfont_scale = 2 font = cv2.FONT_HERSHEY_PLAIN while True: ret, frame = cap.read() # Read the current frame from the video frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5) # Resize the frame ClassIndex, confidence, bbox = model.detect(frame, ‚Ä¶","date":1686355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686355200,"objectID":"8410c0f8b9b150d7f0f816e00c9eca12","permalink":"https://rezamehrizi.github.io/project/object-detection/","publishdate":"2023-06-10T00:00:00Z","relpermalink":"/project/object-detection/","section":"project","summary":"The purpose of this project is to deploy a Python-based application for object detection within both images and videos. Leveraging the powerful capabilities of the OpenCV library, this code employs a range of its methods to accurately locate and track objects of interest.","tags":["Object Detection","Computer Vision","Deep Learning"],"title":"Smart Object Detection and Tracking using OpenCV","type":"project"},{"authors":null,"categories":null,"content":"Statistical analysis often involves identifying sudden changes in time series signals. In this project, I will employ the Pattern Recovery Using Trend Filtering (PRUTF) anomaly detection method, which we introduced in this paper. Afterward, I will discuss performing post-selection statistical inference for the anomalies estimated using PRUTF, as detailed in our post-selection inference paper. In the following, I will provide a concise overview of the methods presented in these papers and subsequently apply them to the Coronavirus Disease (COVID-19) pandemic dataset.\nOverview of PRUTF and Post-Selection Inference Overview of PRUTF: The paper Detection of Change Points in Piecewise Polynomial Signals Using Trend Filtering proposes a new methodology called Pattern Recovery Using Trend Filtering (PRUTF) for identifying unknown change points in piecewise polynomial signals with no continuity restrictions at the change point locations. The paper considers a univariate signal plus noise model, where the signal is deterministic and unknown, with equally spaced input points over the unit interval. Additionally, it is assumed that the signal undergoes unpredictable and distinct changes. With this setup, the objective of this anomaly detection analysis is to estimate the number of anomalies as well as their locations.\nOur approach, PRUTF, is inspired by Tibshirani‚Äôs method but introduces a modification to accelerate the algorithm‚Äôs implementation. PRUTF identifies change points at each regularization parameter level and removes some dual variable coordinates after each change point, ensuring independent dual variables between neighboring change points. The paper establishes a stopping criterion crucial for PRUTF‚Äôs operation. Notably, the dual variables of trend filtering between consecutive change points form a Gaussian bridge process, allowing the introduction of a termination threshold for the algorithm. However, in cases of a staircase pattern in the signal, the method becomes statistically inconsistent. To address this, the paper proposes a modification to PRUTF, providing consistent estimates for both the number and location of change points.\nOverview of Post-Selection Inference for PRUTF: The second paper, Valid Post-Detection Inference for Change Points Identified Using Trend Filtering,mainly focuses on a statistical analysis of anomalies estimated by the PRUTF algorithm. It develops a methodology to perform statistical inference, such as computing p-values and constructing confidence intervals in the newly developed post-selection inference framework. Our work concerns both cases of known and unknown error variance. As pointed out in the post-selection inference literature, the length of such confidence intervals is undesirably long. To resolve this shortcoming, we are also providing two novel strategies, global post-detection and local post-detection which are based on the intrinsic properties of anomalies.\nIn this paper, we have made significant contributions, starting with the characterization of the set of anomalies identified by the PRUTF algorithm as a polyhedral set. This innovation facilitates post-selection inference methods for statistical analysis after anomaly detection. Additionally, we introduced a polyhedral stopping criterion for the PRUTF algorithm, derived from the Gaussian bridge property of dual variables, extending its applicability to post-detection inference. We proposed two test statistics‚Äîone for known noise variance and another for unknown noise variance‚Äîwith exact and finite sample distributions under the null hypothesis. These statistics enable inference on the significance of PRUTF-identified anomalies. However, we observed that confidence intervals produced by these methods tend to be excessively wide, which can reduce the power of hypothesis tests. To address this issue, we introduced two novel conditioning methods for post-detection inference. The first method is ‚Äúlocal post-detection,‚Äù which focuses solely on the target anomaly independently of others, while the second is ‚Äúglobal post-detection,‚Äù emphasizing the analysis of the entire set of anomalies.\nApplication to the Covid-19 Pandemic Dataset The COVID-19 pandemic has had a profound impact worldwide, straining public health systems and disrupting societies and economies. Countries around the globe had implemented various regional and national policies, such as declaring national emergencies, imposing quarantines, and conducting mass testing, in a collective effort to slow down the transmission rate. Governments were keenly interested in comprehending the dynamics of the pandemic and assessing the efficacy of these measures. This understanding can be gleaned by analyzing COVID-19 infection data. Anomaly detection serves as a valuable framework for studying the patterns in COVID-19 infection curves. By identifying the points at which these curves change significantly, anomaly analysis provides insights into shifts in ‚Ä¶","date":1682553600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682553600,"objectID":"7bc4a10cb372951579bb742a1324624f","permalink":"https://rezamehrizi.github.io/project/change-point/","publishdate":"2023-04-27T00:00:00Z","relpermalink":"/project/change-point/","section":"project","summary":"This project aims to discover hidden anomalies in data to improve system integrity by mastering anomaly detection, combined with root cause analysis.","tags":["Deep Learning","Changepoint Detectgion"],"title":"Anomaly Detection and Root Cause Analysis","type":"project"},{"authors":["Reza Mehrzi","Shojaeddin Chenouri"],"categories":null,"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"a5afc677ca9a12a7c3ec5dd36879c0d0","permalink":"https://rezamehrizi.github.io/publication/preprint1/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/publication/preprint1/","section":"publication","summary":"This study addresses statistical inference for change point detection using the PRUTF algorithm. It introduces methods for computing p-values, constructing confidence intervals, and proposes strategies to improve their precision. Evaluation is performed on real and simulated data.","tags":["Source Themes"],"title":"Valid Post-Detection Inference for Change Points Identified Using Trend Filtering","type":"publication"},{"authors":["Reza Mehrzi","Shojaeddin Chenouri"],"categories":null,"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"957f467e8471e6fcee579e2cd5755e24","permalink":"https://rezamehrizi.github.io/publication/preprint2/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/publication/preprint2/","section":"publication","summary":"This paper introduces PRUTF, a method using trend filtering for change point detection in piecewise polynomial signals. PRUTF offers a dual solution path for efficient stopping rules and consistent pattern recovery, even in the presence of consecutive change points. Its effectiveness is demonstrated across various signals and compared with state-of-the-art methods using real-world datasets.","tags":["Source Themes"],"title":"Detection of Change Points in Piecewise Polynomial Signals Using Trend Filtering","type":"publication"},{"authors":["Reza Mehrzi","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"import libr print(\u0026#39;hello\u0026#39;) Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://rezamehrizi.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy Reza, the website builder for Hugo","type":"post"},{"authors":null,"categories":null,"content":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you‚Äôll find some examples of the types of technical content that can be rendered with Wowchemy.\nExamples Code Wowchemy supports a Markdown extension for highlighting code syntax. You can customize the styles under the syntax_highlighter option in your config/_default/params.yaml file.\n```python\rimport pandas as pd\rdata = pd.read_csv(\u0026#34;data.csv\u0026#34;)\rdata.head()\r```\rrenders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Mindmaps Wowchemy supports a Markdown extension for mindmaps.\nSimply insert a Markdown markmap code block and optionally set the height of the mindmap as shown in the example below.\nA simple mindmap defined as a Markdown list:\n```markmap {height=\u0026#34;200px\u0026#34;}\r- Hugo Modules\r- wowchemy\r- wowchemy-plugins-netlify\r- wowchemy-plugins-netlify-cms\r- wowchemy-plugins-reveal\r```\rrenders as\n- Hugo Modules\r- wowchemy\r- wowchemy-plugins-netlify\r- wowchemy-plugins-netlify-cms\r- wowchemy-plugins-reveal A more advanced mindmap with formatting, code blocks, and math:\n```markmap\r- Mindmaps\r- Links\r- [Wowchemy Docs](https://wowchemy.com/docs/)\r- [Discord Community](https://discord.gg/z8wNYzb)\r- [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes)\r- Features\r- Markdown formatting\r- **inline** ~~text~~ *styles*\r- multiline\rtext\r- `inline code`\r-\r```js\rconsole.log(\u0026#39;hello\u0026#39;);\rconsole.log(\u0026#39;code block\u0026#39;);\r```\r- Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$\r```\rrenders as\n- Mindmaps\r- Links\r- [Wowchemy Docs](https://wowchemy.com/docs/)\r- [Discord Community](https://discord.gg/z8wNYzb)\r- [GitHub](https://github.com/wowchemy/wowchemy-hugo-themes)\r- Features\r- Markdown formatting\r- **inline** ~~text~~ *styles*\r- multiline\rtext\r- `inline code`\r-\r```js\rconsole.log(\u0026#39;hello\u0026#39;);\rconsole.log(\u0026#39;code block\u0026#39;);\r```\r- Math: $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ Charts Wowchemy supports the popular Plotly format for interactive charts.\nSave your Plotly JSON in your page folder, for example line-chart.json, and then add the {{\u0026lt; chart data=\u0026#34;line-chart\u0026#34; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\nYou might also find the Plotly JSON Editor useful.\nMath Wowchemy supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.yaml file.\nTo render inline or block math, wrap your LaTeX math with {{\u0026lt; math \u0026gt;}}$...${{\u0026lt; /math \u0026gt;}} or {{\u0026lt; math \u0026gt;}}$$...$${{\u0026lt; /math \u0026gt;}}, respectively. (We wrap the LaTeX math in the Wowchemy math shortcode to prevent Hugo rendering our math as Markdown. The math shortcode is new in v5.5-dev.)\nExample math block:\n{{\u0026lt; math \u0026gt;}} $$ \\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2} $$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$\rExample inline math {{\u0026lt; math \u0026gt;}}$\\nabla F(\\mathbf{x}_{n})${{\u0026lt; /math \u0026gt;}} renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the math linebreak (\\\\):\n{{\u0026lt; math \u0026gt;}} $$f(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\ 1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}$$ {{\u0026lt; /math \u0026gt;}} renders as\n$$\rf(k;p_{0}^{*}) = \\begin{cases}p_{0}^{*} \u0026amp; \\text{if }k=1, \\\\\r1-p_{0}^{*} \u0026amp; \\text{if }k=0.\\end{cases}\r$$\rDiagrams Wowchemy supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid\rgraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2]\r```\rrenders as\ngraph TD\rA[Hard] --\u0026gt;|Text| B(Round)\rB --\u0026gt; C{Decision}\rC --\u0026gt;|One| D[Result 1]\rC --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid\rsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good!\r```\rrenders as\nsequenceDiagram\rAlice-\u0026gt;\u0026gt;John: Hello John, how are you?\rloop Healthcheck\rJohn-\u0026gt;\u0026gt;John: Fight against hypochondria\rend\rNote right of John: Rational thoughts!\rJohn--\u0026gt;\u0026gt;Alice: Great!\rJohn-\u0026gt;\u0026gt;Bob: How about you?\rBob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid\rgantt\rsection Section\rCompleted :done, des1, 2014-01-06,2014-01-08\rActive :active, des2, 2014-01-07, 3d\rParallel 1 : des3, after des1, 1d\rParallel 2 : des4, after des1, 1d\rParallel 3 : des5, after des3, 1d\rParallel 4 : des6, after des4, 1d\r```\rrenders ‚Ä¶","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://rezamehrizi.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Wowchemy is designed to give technical content creators a seamless experience. You can focus on the content and Wowchemy handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Markdown","type":"post"},{"authors":["Reza Mehrzi"],"categories":[],"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic!\rInstall Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post\u0026#39;s title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post‚Äôs folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://rezamehrizi.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://rezamehrizi.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Reza Mehrzi","Akbar Asgharzadeh","Mohammad Z Raqab"],"categories":null,"content":"","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"d5d20be84aa461b6d2f1df8ef2a1336c","permalink":"https://rezamehrizi.github.io/publication/journal-article2/","publishdate":"2019-02-01T00:00:00Z","relpermalink":"/publication/journal-article2/","section":"publication","summary":"In this article, we consider the prediction of future failure times based on Type-I hybrid censored samples. Point predictors and prediction intervals using different procedures are discussed for a general model. The exponential and Rayleigh distributions are used as illustrative examples to show the most simplified forms of the so obtained predictors as well as prediction intervals. Intensive simulation study and a real life dataset are presented to illustrate our findings and results.","tags":["Source Themes"],"title":"Prediction of future failures times based on Type-I hybrid censored samples of random sample sizes","type":"publication"},{"authors":["Reza Mehrzi","Mohammad Z Raqab","Akbar Asgharzadeh","FA Alqallaf"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"114eb2cc5a80e7a63a7ad85ac647049c","permalink":"https://rezamehrizi.github.io/publication/journal-article3/","publishdate":"2018-07-01T00:00:00Z","relpermalink":"/publication/journal-article3/","section":"publication","summary":"In survival, reliability and medical studies, it is natural to have experience with several situations pertaining to testing, cost or money constraints where the removal of units prior to failure is preplanned. In this context, we consider the inference problem including estimation and prediction for power Lindley distribution under the progressively type-II censored sample data. For the estimation purposes and other reliability characteristics maximum likelihood and Bayes approaches for estimating the model parameters are considered in this paper. Confidence intervals of the parameters and the corresponding average lengths and coverage probabilities are developed based on maximum likelihood and Bayes techniques. The Gibbs and Metropolis samplers are used to predict the life lengths of the removed units in multiple stages of the progressively censored sample. Monte Carlo simulations are performed to compare different methods and one real data set is analyzed for illustrative purposes.","tags":["Source Themes"],"title":"Estimation and prediction for power Lindley distribution under progressively type II right censored samples","type":"publication"}]